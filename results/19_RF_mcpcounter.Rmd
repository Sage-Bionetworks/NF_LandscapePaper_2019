---
title: "RF_MCPCounter"
author: "Jineta Banerjee"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
  html_document:
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    fig_width: 7
    fig_height: 6
    fig_caption: true
    df_print: paged
    code_folding: hide
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, eval=TRUE, results='hide', message=FALSE, warning=FALSE, include=FALSE}

library(synapser)
library(synapserutils)
library(BiocManager)

library(tidyverse)
library(DT)
library(colorspace)
library(RColorBrewer)
library(wesanderson)

#Random Forest
library(randomForest)
library(e1071)
library(caret)

#plotting
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)
library(pheatmap)

library(AnnotationDbi)
#library(hgu95av2.db)
#library(STRINGdb)
library(gridExtra)

#renv::init()
library(glue)

#Synapser
synLogin()
```


```{r make color palette}

## Make colors for plots
fabcolors = RColorBrewer::brewer.pal(n = 11,name = 'RdGy')
col1 = RColorBrewer::brewer.pal(n = 10,name = 'PRGn')
col2 = RColorBrewer::brewer.pal(n = 10,name = 'Spectral')
col3 = RColorBrewer::brewer.pal(n = 10,name = 'BrBG')
col4 = RColorBrewer::brewer.pal(n = 10,name = 'PiYG')
col5 = RColorBrewer::brewer.pal(n = 10,name = 'PuOr')
col6 = RColorBrewer::brewer.pal(n = 10,name = 'RdBu')


allcolors <- c(fabcolors, col1,col2,col3, col4, col5, col6)
allcolors <- list(allcolors)

morecolors1 <- wes_palette("Darjeeling1", n=4, type = "discrete")
morecolors1 <- list(morecolors1)

morecolors2 <- wes_palette("Moonrise2", n=3, type = "discrete")
morecolors2 <- list(morecolors2)

color_list <- c(allcolors, morecolors1, morecolors2)

```

## Introduction

This document describes training a random forest model using sample-wise immune cell signatures generated by [mcp counter](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1070-5) using RNASeq data as its input features. We chose to train a random forest classifier to identify NF tumortypes using the mcp counter signatures for the following features of the model :

* robustness to high dimensionality data
* ability to handle unbalanced classes
* robustness to outliers and non-linear data
* quick training /prediction speeds
* low bias and moderate variance

Our goal is to find important latent variables that classify the various tumorTypes. We will then inspect the classifying features to find meaningful genesets that distinguish between two tumortypes.

Tumortypes represented in the data:

* Plexiform Neurofibroma
* MPNST
* Cutaneous Neurofibroma
* Neurofibroma
* HGG
* LGG

```{r download data from Synapse, eval=TRUE, results='hide', message=FALSE, warning=FALSE, include=FALSE}

#download data: MCP counter immune cell sigs
mcp_counter <- synTableQuery("SELECT * FROM syn20710536 WHERE method = 'mcp_counter' ")$asDataFrame() %>%
  dplyr:: select(cell_type, tumorType, specimenID, sex, score)

#Clean up tumortypes
mcp_counter$tumorType[mcp_counter$tumorType == "Malignant peripheral nerve sheath tumor"] <- "Malignant Peripheral Nerve Sheath Tumor"
mcp_counter$tumorType[mcp_counter$tumorType == "Schwannoma" | mcp_counter$tumorType == "Meningioma" | mcp_counter$tumorType == "Ependymoma"] <- "NF2"


#Restrict dataset to NF1 tumors
mcp_select <- mcp_counter %>% 
  dplyr::filter(tumorType != "NF2"  & tumorType != "Ganglioglioma" & tumorType != "Other")

# Re form the data
keep <- c("cell_type", "score", "specimenID")
mcp_forest <- mcp_select[ ,keep] %>%
  group_by_at(vars(-score)) %>%  # group by everything other than the value column.
  mutate(row_id=1:n()) %>% ungroup() %>%  # build group index
  spread(key=cell_type, value=score) %>%    # spread
  dplyr::select(-row_id)   # drop the index 

specimen_tumortype <- unique(mcp_select[,c("specimenID", "tumorType")])

forest_data <- merge(mcp_forest, specimen_tumortype, by = "specimenID")
rownames(forest_data) <- forest_data$specimenID
forest_data$tumorType <- as.factor(forest_data$tumorType)
forest_data <- forest_data[,2:ncol(forest_data)]


```


## Partitioning the data into training and testing set:

The dataset was split into 75% training and 25% testing dataset. The function _createDataPartition_ is used to create balanced splits of the data. Since the _tumorType_ argument to this function is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.

```{r split the data for training, eval=TRUE}

#Make the test and training datasets
#set.seed(998)  (if you want to keep the exact same training and testing dataset then uncomment this line)
inTraining <- createDataPartition(as.factor(forest_data$tumorType), p = .75, list = FALSE)

training <- forest_data[ inTraining,]
testing  <- forest_data[-inTraining,]

```

## Model training and Crossvalidation :

We first trained an initial model on the training dataset using iterative _mtrys_ and 1000 trees. The model was crossvalidated using 5-fold crossvalidation technique.

Below are details of our initial model.

```{r create model and check fit, eval=TRUE, fig.height=10, fig.width=10, message=FALSE, warning=FALSE}


## Load Fit data (The Model described in this document is stored on Synapse)
#load(synGet("syn21201190")$path)

# 10 fold validation control
fitControl <- trainControl(## 5-fold CV
                           method = "repeatedcv",
                           number = 5,
                           ## repeated ten times
                           repeats = 5)

tunegrid <- expand.grid(.mtry=c(1:10))

#Find the classes:
print("Summary of classes in training data")
summary(training$tumorType)


## Construct the random forest model called Fit (the code is commented out to facilitate quick rendering of html file by loading the Fit from Synapse)

# set.seed(9998)
Fit_init <- train(tumorType ~ .,
             data = training[,c(1:ncol(training))],
             method = "rf",
             ntree= 1000,
             #mtry= c(1:10)
             tuneGrid = tunegrid,
             #classwt =
             proximity=TRUE,
             importance = TRUE,
             trControl = fitControl,
             verbose = TRUE)

print("Check the fit of theinitial model")                 
Fit_init

#plot the model
theme_update(text = element_text(size=20))
ggplot(Fit_init$results,  aes(x=mtry, y=Accuracy)) +
  geom_point(aes(size=2)) +
  geom_line() +
  coord_cartesian(ylim = c(0,1)) +
  labs(main="The model", x="mtry :: Number of features for each split", y= "Accuracy of the model") 

print("Check the clustering of the samples according to the model")
MDSplot(Fit_init$finalModel, 
        as.factor(training$tumorType), 
        k=2, palette=NULL, 
        pch=as.numeric(training$tumorType), 
        cex=2, 
        cex.axis= 1.5,
        cex.lab = 1.5,
        cex.main = 1.5,
        main= "MDS Plot of the classified training set")
legend("topright",
       inset=0.01, 
       cex= 1.0,
       legend=levels(training$tumorType), 
       fill=brewer.pal(6, "Set1"))

```


```{r predict model, eval=TRUE}

#Use model to predict labels of test data
pred <- predict(Fit_init, newdata = testing[,c(1:length(colnames(testing)))])

#store predicted labels in the test dataframe
testing$pred <- pred

```


```{r model accuracy, eval=TRUE}

# Check the accuracy of the model
library(DT)

conf_matrix <- confusionMatrix(data = testing$pred, 
                              reference = as.factor(testing$tumorType), 
                              mode = "prec_recall")

#conf_matrix

## Make a performance histogram from initial iterations of the forest

perf <- as.data.frame(conf_matrix$byClass)
perf$Class <- rownames(perf)
perf <- perf %>%
  dplyr::select(Class, F1)

#conf_matrix$table

```

## Iterating over models

We observed that tuning our model did not significantly improve the performance of the initial model. As a result we tried an ensemble approach and plot the performances of all possible models.

```{r Make a model iteratively, fig.width=8, fig.height=8, message=FALSE, warning=FALSE}


FeatureList <- list()
perf_new <- perf

# Load the Featurelist and perf list stored on synapse
load(synGet("syn21246234")$path)

#The model building code has been commented out below for quick rendering of html

# for (i in 1:500){
#   # make new train-test set
#   inTraining <- createDataPartition(as.factor(forest_data$tumorType), p = .75, list = FALSE)
#   training <- forest_data[ inTraining,]
#   testing  <- forest_data[-inTraining,]
#   
#   #make new model
#   Fit_new <- train(tumorType ~ .,
#              data = training[,c(1:ncol(training))],
#              method = "rf",
#              ntree= 1000,
#              #tuneGrid = tunegrid,
#              #classwt =
#              proximity=TRUE,
#              importance = TRUE,
#              trControl = fitControl,
#              verbose = TRUE)
#   
#   # predict test set with the model to get F1 scores
#   pred <- predict(Fit_new, newdata = testing[,c(1:length(colnames(testing)))])
#   #store predicted labels in the test dataframe
#   testing$pred <- pred
#   
#   #Make confusion matrix
#   conf_matrix <- confusionMatrix(data = testing$pred, 
#                               reference = as.factor(testing$tumorType), 
#                               mode = "prec_recall")
#   
#   ## Store F1 scores from various iterations of the forest
#   df <- as.data.frame(conf_matrix$byClass)
#   perf_new[, glue('Iter{i}')] <- df$F1
#   #perf[, Class] <- rownames(df)
#   
#   
#   #Store Feature importance for all iterations in a list
#   # estimate variable importance
#   importance <- varImp(Fit_new, scale=FALSE)
# 
#   # Select top important features
#   features <- as.data.frame(importance$importance)
#   
#   FeatureList[[i]] <- (features)
# }


# Plot histogram of all F1 scores
#Make long df
perf_new$Class <- as.factor(perf_new$Class)
perf_new_long <- gather(perf_new, iteration, All_scores, F1:Iter500, factor_key=TRUE)

par(mfrow=c(2,1)) 

theme_update(text = element_text(size = 10))

ggplot(perf_new_long, aes(x=All_scores, fill=Class, color=Class)) + 
  geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  #geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Histogram of F1 scores for iterations of RF",x="F1 score", y = "Counts") +
  theme(text = element_text(size=10)) +
  theme(axis.text.x  = element_text(size=10)) +
  theme(axis.text.y = element_text(size=10))

ggplot(perf_new_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Density plot of F1 scores for iterations of RF",x="F1 score", y = "Counts") +
  theme(text = element_text(size=10)) +
  theme(axis.text.x  = element_text(size=10)) +
  theme(axis.text.y = element_text(size=10))
  

```

## Feature Importance evaluation

We also saved the features deemed important for each of the iterations of the model for each of our classes. We plot the scores of each of the features in each of our models.

```{r histogram of features, fig.width=8, fig.height=8, message=FALSE, warning=FALSE}

# Plot a distribution of importance of features

features_cNF <- as.data.frame(sapply(FeatureList, `[[`, 1))
features_cNF$Class <- rownames(FeatureList[[1]])
cNF_long <- gather(features_cNF, iteration, All_scores, V1:V500, factor_key=TRUE)

theme_update(text = element_text(size = 10))
ggplot(cNF_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in cNF",x="Importance", y = "Counts") 
  


features_HGG <- as.data.frame(sapply(FeatureList, `[[`, 2))
features_HGG$Class <- rownames(FeatureList[[1]])
HGG_long <- gather(features_HGG, iteration, All_scores, V1:V500, factor_key=TRUE)
ggplot(HGG_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in HGG",x="Importance", y = "Counts") 


features_LGG <- as.data.frame(sapply(FeatureList, `[[`, 3))
features_LGG$Class <- rownames(FeatureList[[1]])
LGG_long <- gather(features_LGG, iteration, All_scores, V1:V500, factor_key=TRUE)
ggplot(LGG_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in LGG",x="Importance", y = "Counts") 


features_MPNST <- as.data.frame(sapply(FeatureList, `[[`, 4))
features_MPNST$Class <- rownames(FeatureList[[1]])
MPNST_long <- gather(features_MPNST, iteration, All_scores, V1:V500, factor_key=TRUE)
ggplot(MPNST_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in MPNST",x="Importance", y = "Counts") 


features_NF <- as.data.frame(sapply(FeatureList, `[[`, 5))
features_NF$Class <- rownames(FeatureList[[1]])
NF_long <- gather(features_NF, iteration, All_scores, V1:V500, factor_key=TRUE)
ggplot(NF_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in NF",x="Importance", y = "Counts") 


features_pNF <- as.data.frame(sapply(FeatureList, `[[`, 6))
features_pNF$Class <- rownames(FeatureList[[1]])
pNF_long <- gather(features_pNF, iteration, All_scores, V1:V500, factor_key=TRUE)
ggplot(pNF_long, aes(x=All_scores, fill=Class, color=Class)) + 
  #geom_histogram( binwidth=0.05, alpha=0.5, position="dodge") +
  geom_density(alpha=.2) +
  theme(legend.position="top") +
  #scale_color_manual(values=allcolors[[1]][12:18])
  scale_color_brewer(palette="Spectral")+
  scale_fill_brewer(palette="Spectral") +
  labs(title="Importance of features in pNF",x="Importance", y = "Counts")




#save(FeatureList, perf_new, file = "RF_mcpcounter.RData")
  
```

```{r sessionInfo, eval=T}

sessionInfo()

```
